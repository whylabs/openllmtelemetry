[tool.poetry]
name = "OpenLLMTelemetry"
version = "0.0.1.b4"
description = "End-to-end observability with built-in security guardrails."
authors = ["WhyLabs.ai <support@whylabs.ai>"]
license = "Apache-2.0"
readme = "README.md"

[tool.poetry.dependencies]
python = ">=3.8.1,<4.0"
opentelemetry-api = "^1.21.0"
opentelemetry-sdk = "^1.21.0"
opentelemetry-exporter-otlp-proto-http = "^1.22.0"
opentelemetry-instrumentation-requests = "^0.43b0"
openai = {version = ">0.7,<2.0", optional = true}
boto3 = {version = "^1.18.67", optional = true}
whylogs-container-client = "^1.0.12"

[tool.poetry.group.dev.dependencies]
pytest = "^7.4.3"
flake8 = { version = "^6.1.0", python = ">=3.8.1,<4" }
pre-commit = "^3.5.0"
ipykernel = "^6.27.1"
pyright = "1.1.342"
ruff = "^0.1.7"
sphinx = "7.1.2"
furo = "^2023.8.19"

[tool.poetry.extras]
openai = [
    "openai"
]

bedrock = [
    "boto3"
]

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"

[tool.pyright]
include = ["openllmtelemetry", "tests"]
exclude = ["openllmtelemetry/instrumentation"]
typeCheckingMode = "strict"

reportMissingTypeStubs = false
reportMissingParameterType = false
reportMissingTypeArgumet = false

[tool.ruff]
line-length = 140
indent-width = 4
include = ["./openllmtelemetry/**/*.py", "./tests/**/*.py", "./integ/**/*.py", "./scripts/**/*.py"]
select = ["E", "F", "I", "W"]

[tool.ruff.isort]
known-first-party = ["whylogs", "langkit"]


[tool.ruff.lint]
fixable = ["ALL"]
dummy-variable-rgx = "^(_+|(_+[a-zA-Z0-9_]*[a-zA-Z0-9]+?))$"

[tool.ruff.format]
quote-style = "double"
indent-style = "space"
skip-magic-trailing-comma = false
line-ending = "auto"